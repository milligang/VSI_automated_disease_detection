{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import glob\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from custom_functions import FD_calculation, cross_val_prediction, network_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### To select a dataset to analyze, uncomment all code under the dataset's name\n",
    "\n",
    "### Expert #1\n",
    "'''dataset = \"STARE1\"\n",
    "nefi_output_folder = \"../Data/Dataset_1/NEFI_graphs/*/\"\n",
    "image_folder = \"../Data/Dataset_1/Provided_masks/\"\n",
    "write_folder = \"../Results/Dataset_1/\"'''\n",
    "\n",
    "###Expert #2\n",
    "'''dataset = \"STARE2\"\n",
    "nefi_output_folder = \"../Data/Dataset_1/NEFI_graphs_VK/*/\"\n",
    "image_folder = \"../Data/Dataset_1/Provided_masks_VK/\"\n",
    "write_folder = \"../Results/Dataset_1_VK/\"'''\n",
    "\n",
    "###HRF\n",
    "dataset = \"HRF\"\n",
    "nefi_output_folder = \"../Data/HRF_Dataset_1/NEFI_graphs/*/\"\n",
    "image_folder = \"../Data/HRF_Dataset_1/Provided_masks/\"\n",
    "write_folder = \"../Results/HRF_Dataset_1/\"\n",
    "\n",
    "### all\n",
    "'''dataset = \"all\"\n",
    "nefi_output_folder = \"../Data/all/NEFI_graphs/*/\"\n",
    "image_folder = \"../Data/all/Provided_masks/\"\n",
    "write_folder = \"../Results/all/\"'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record fractal dimension, standard descriptors of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"im\"\n",
    "nefi_outputs = glob.glob(f\"{nefi_output_folder}*.txt\")\n",
    "\n",
    "FDs = []\n",
    "log_Ns = []\n",
    "nodes = []\n",
    "edges = []\n",
    "edge_lengths = []\n",
    "y = []\n",
    "\n",
    "if dataset == \"HRF\":\n",
    "    nums = np.arange(1,46)\n",
    "    mat = np.load(\"../Data/Diagnoses/image_diagnoses_HRF.npy\",allow_pickle=True).item()\n",
    "elif \"STARE\" in dataset:\n",
    "    nums = np.array([1,2,3,4,5,44,77,81,82,139,162, 163, 235, 236, 239, 240, 255, 291, 319, 324])\n",
    "    mat = np.load(\"../Data/Diagnoses/image_diagnoses.npy\",allow_pickle=True).item()    \n",
    "elif \"all\" in dataset:    \n",
    "    mat = np.load(\"../Data/Diagnoses/image_diagnoses_all.npy\",allow_pickle=True).item()    \n",
    "    nums = list(mat['image_diagnoses'].keys())\n",
    "\n",
    "for num in nums:\n",
    "    \n",
    "    print(num)\n",
    "    \n",
    "    if \"all\" in dataset:\n",
    "        num_str = num\n",
    "    else:\n",
    "        num_str = f\"{str(num).zfill(4)}\"\n",
    "    \n",
    "    #load in image\n",
    "    image_loc = f\"{image_folder}{file_name}{num_str}.png\"\n",
    "    image = mpimg.imread(image_loc)\n",
    "    \n",
    "    #compute Fractal dimension\n",
    "    try:\n",
    "        FD, log_N, Hs = FD_calculation(image[:,:])\n",
    "    except:\n",
    "        FD, log_N, Hs = FD_calculation(image[:,:,0])\n",
    "            \n",
    "    #compute network descriptors\n",
    "    \n",
    "    #find nefi output file\n",
    "    nefi_output = [s for s in nefi_outputs if num_str in s]\n",
    "    #ensure there is only one location in this list\n",
    "    assert len(nefi_output)==1\n",
    "    #read in graph\n",
    "    graph_in = nx.read_multiline_adjlist(nefi_output[0],delimiter='|')\n",
    "    edges_tmp, nodes_tmp, edge_lengths_tmp = network_descriptors(graph_in)\n",
    "    \n",
    "    #find classification\n",
    "    classification = 1*(0 in mat['image_diagnoses'][num_str])\n",
    "    \n",
    "    #record each entry\n",
    "    FDs.append(FD)\n",
    "    log_Ns.append(log_N)\n",
    "    edges.append(edges_tmp)\n",
    "    nodes.append(nodes_tmp)\n",
    "    edge_lengths.append(edge_lengths_tmp)\n",
    "    y.append(classification)\n",
    "\n",
    "    #save FD, box-counting for later use\n",
    "    data = {}\n",
    "    data['FD'] = FD\n",
    "    data['Boxcounting'] = log_N\n",
    "    save_filename = f\"{write_folder}DS1_im{num_str}_FD_results.npy\"\n",
    "    np.save(save_filename,data)\n",
    "    \n",
    "#convert lists to arrays    \n",
    "FDs = np.array(FDs)[:,None]\n",
    "log_Ns = np.array(log_Ns)\n",
    "edges = np.array(edges)[:,None]\n",
    "nodes = np.array(nodes)[:,None]\n",
    "edge_lengths = np.array(edge_lengths)[:,None]\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute average fractal dimension values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_fd = np.mean(FDs[y==1])\n",
    "normal_sd = np.std(FDs[y==1])\n",
    "\n",
    "dis_fd = np.mean(FDs[y==0])\n",
    "dis_sd = np.std(FDs[y==0])\n",
    "\n",
    "print(f\"Normal FD mean: {normal_fd}%, \\pm {normal_sd}\")\n",
    "print(f\"Diseased FD mean: {dis_fd}%, \\pm {dis_sd}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptors = [edges, edge_lengths, nodes]\n",
    "descriptor_strings = [\"edges\", \"lengths\", \"nodes\"]\n",
    "\n",
    "for d,v in zip(descriptors,descriptor_strings):\n",
    "    normal_fd = np.mean(d[y==1])\n",
    "    normal_sd = np.std(d[y==1])\n",
    "\n",
    "    dis_fd = np.mean(d[y==0])\n",
    "    dis_sd = np.std(d[y==0])\n",
    "\n",
    "    print(f\"Normal {v} mean: {normal_fd}%, \\pm {normal_sd}\")\n",
    "    print(f\"Diseased {v} mean: {dis_fd}%, \\pm {dis_sd}\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification by scalar values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Df\", \"Avg. Edge Length\", \"# Nodes\", \"# Edges\"]\n",
    "\n",
    "X = np.hstack([FDs, edge_lengths, nodes, edges])\n",
    "\n",
    "#normalize\n",
    "X_norm = X - X.mean(axis=0)\n",
    "X_norm /= X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(4):\n",
    "    print(cross_val_prediction(X_norm[:,i:i+1],y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification by log_N (box counting vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = log_Ns\n",
    "\n",
    "#normalize\n",
    "X_norm = X - X.mean(axis=0)\n",
    "#perform PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "#perform 5-fold cross validation)\n",
    "\n",
    "print(cross_val_prediction(X_pca,y))\n",
    "\n",
    "'''plt.figure()\n",
    "plt.plot(log_Ns[y==0,:].T,\"r\")\n",
    "plt.plot(log_Ns[y==1,:].T,\"b\")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Box counting vector figure depiction (tailored to HRF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 18\n",
    "\n",
    "scales = np.logspace(0, \n",
    "                     np.log2(np.min(image.shape)/2), \n",
    "                     num=10, \n",
    "                     endpoint=True, \n",
    "                     base=2)\n",
    "#ensure integer valued box sizes\n",
    "scales = np.array([np.floor(s) for s in scales],dtype=int)\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "\n",
    "for ax in [ax1,ax2]:\n",
    "    ax.loglog(scales,np.exp(log_Ns[y==0,:].T),\"r--\")\n",
    "    ax.loglog(scales,np.exp(log_Ns[y==1,:].T),\"b\")\n",
    "\n",
    "ax1.plot([1e7,1e7],[1e6,1e6],\"b\",label=\"Normal\")\n",
    "ax1.plot([1e7,1e7],[1e6,1e6],\"r--\",label=\"Diseased\")\n",
    "ax1.legend(fontsize=fontsize,loc=1)\n",
    "ax1.set_xlim([.8, 2e3])\n",
    "ax1.set_ylim([1e0, 2e6])\n",
    "\n",
    "c = plt.Rectangle((.9,5e4), 4e0-.9, 1e6-5e4, facecolor='None', edgecolor = \"k\", linewidth=2)\n",
    "ax1.add_patch(c)\n",
    "\n",
    "ax1.set_xlabel(\"Box side length $(s)$\", fontsize=fontsize)\n",
    "ax1.set_ylabel(\"Nonzero box count $(N(s))$\", fontsize=fontsize)\n",
    "ax1.set_title(\"HRF box-counting vectors by disease\",fontsize=fontsize)    \n",
    "\n",
    "ax2.set_title(\"Zoomed in\",fontsize=fontsize)    \n",
    "ax2.set_xlim([.9, 4e0])\n",
    "ax2.set_ylim([5e4, 1e6])\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "plt.minorticks_off()\n",
    "\n",
    "plt.savefig(f\"../Figures/box_counting_hist_{dataset}.pdf\",format=\"pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Df computation figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize=10\n",
    "\n",
    "if len(image.shape) == 3: image = image[:,:,0]\n",
    "\n",
    "#image dimensions\n",
    "im_shape = image.shape\n",
    "im_min_shape = np.min(im_shape)\n",
    "\n",
    "#create logscale for s -- starts with s=1 and \n",
    "#ends with (smaller length of image) / 2.\n",
    "scales = np.logspace(0, \n",
    "                     np.log2(im_min_shape/2), \n",
    "                     num=10, \n",
    "                     endpoint=True, \n",
    "                     base=2)\n",
    "#ensure integer valued box sizes\n",
    "scales = np.array([np.floor(s) for s in scales],dtype=int)\n",
    "#ensure 1 doesn't repeat itself\n",
    "if scales[1] == 1:\n",
    "    scales[1] = 2\n",
    "    \n",
    "coeffs=np.polyfit(np.log(scales), log_Ns[-1], 1)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10,5))\n",
    "\n",
    "for i in np.arange(5):\n",
    "\n",
    "    H = Hs[2*i]\n",
    "    Hy, Hx = H.shape\n",
    "    \n",
    "    ax = fig.add_subplot(2,3,i+2)\n",
    "    ax.imshow(1*(H>0),vmin=0,vmax=1,aspect=\"auto\",cmap=\"bone\")\n",
    "\n",
    "    ax.set_title(f\"$s$ = {scales[2*i]}, N(s) = {int(np.exp(log_Ns[-1][2*i]))}\",fontsize=fontsize)\n",
    "    \n",
    "    if i >=2:\n",
    "        ax.hlines(y = np.arange(0.5,Hy), xmin=-0.5, xmax = Hx, alpha=0.5, linewidth=0.5)\n",
    "        ax.vlines(x = np.arange(0.5,Hx), ymin=-0.5, ymax = Hy, alpha=0.5, linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlim([-.5,Hx-.5])\n",
    "    ax.set_ylim([-.5,Hy-.5])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "ax = fig.add_subplot(2,3,1)    \n",
    "\n",
    "ax.loglog(scales,np.exp(log_Ns[-1]),\".\",label = \"N(s)\")\n",
    "ax.loglog(scales,np.exp(coeffs[1] + coeffs[0]*np.log(scales)), label = f\"$ln(N(s)) = {round(coeffs[1],1)}  {round(coeffs[0],1)}\\ln(s)$\")\n",
    "\n",
    "ax.set_xlabel(\"$s$\",fontsize=fontsize)\n",
    "ax.set_ylabel(\"$N(s)$\",fontsize=fontsize)\n",
    "ax.set_title(\"Fractal dimension calculation\",fontsize=fontsize)\n",
    "ax.legend(fontsize=8)\n",
    "plt.axis(\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
